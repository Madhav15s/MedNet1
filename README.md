# ğŸ¥ MedNet1 â€” Multi-Class Medical AI System

[![Demo](https://img.shields.io/badge/Demo-YouTube-red?style=flat-square&logo=youtube)](https://www.youtube.com/watch?v=l_lQYxWWg9Y)
[![License](https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-blue?style=flat-square&logo=python)](https://python.org)
[![React](https://img.shields.io/badge/React-18+-61DAFB?style=flat-square&logo=react)](https://reactjs.org)

MedNet1 is an AI-powered system for analyzing various medical images across different imaging modalities. It supports multi-class classification and provides accurate predictions, confidence scores, and medically relevant explanations via a modern React frontend.

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Supported Imaging Types](#-supported-imaging-types--classes)
- [Getting Started](#-getting-started)
  - [Prerequisites](#prerequisites)
  - [Backend Setup](#-backend-setup)
  - [Frontend Setup](#-frontend-setup)
- [Project Structure](#-project-structure)
- [Usage](#-usage)
- [Customization](#-customization)
- [Contributing](#-contributing)
- [Disclaimer](#-disclaimer)
- [License](#-license)
- [Acknowledgements](#-acknowledgements)

## âœ¨ Features

- **ğŸ”¬ Multi-Modal Medical Imaging** â€” Supports Chest X-rays, Brain MRIs, Skin Lesions, Retinal Scans, and Cardiac Imaging
- **ğŸ§  Deep Learning Models** â€” Uses ResNet18 with transfer learning for accurate multi-class classification
- **âš¡ React Frontend (Vite)** â€” Fast and responsive UI for easy image uploads and predictions
- **ğŸ“ˆ Performance Metrics** â€” Visualizations like confusion matrices, ROC curves, and accuracy scores
- **ğŸ“Š Confidence Scores** â€” Prediction probabilities for each class to improve trustworthiness
- **ğŸ“ Dataset Setup Utility** â€” One-command setup for standardized dataset directories
- **ğŸ§¾ AI-Generated Medical Explanations** â€” Textual explanation for each diagnosis (prototype stage)

## ğŸ§  Supported Imaging Types & Classes

| Imaging Type     | Classes                                                        |
|------------------|----------------------------------------------------------------|
| **Chest Xâ€‘Ray**     | Normal, Pneumonia, COVIDâ€‘19, Tuberculosis, Lung Cancer        |
| **Brain MRI**       | Normal, Tumor, Stroke, Hemorrhage, Multiple Sclerosis         |
| **Skin Lesion**     | Normal, Melanoma, Basal Cell Carcinoma, Squamous Cell Carcinoma |
| **Retinal Image**   | Normal, Diabetic Retinopathy, Glaucoma, Macular Degeneration  |
| **Cardiac Imaging** | Normal, Heart Failure, Arrhythmia, Valve Disease              |

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- Node.js 16 or higher
- npm or yarn package manager
- CUDA-compatible GPU (recommended for training)

### ğŸ“¦ Backend Setup

#### 1. Clone the Repository
```bash
git clone https://github.com/Madhav15s/MedNet1.git
cd MedNet1
```

#### 2. Set Up Python Environment
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
source venv/bin/activate        # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Prepare Dataset
Use the helper function to create a structured dataset directory:

```bash
python -c "from utils.data_utils import create_dataset_structure; create_dataset_structure('chest_xray')"
```

This creates the following structure:
```
datasets/
â””â”€â”€ chest_xray/
    â”œâ”€â”€ train/
    â””â”€â”€ val/
```

**Available dataset types:** `chest_xray`, `brain_mri`, `skin_lesion`, `retinal`, `cardiac`

#### 4. Train Model
```bash
python src/train.py --medical_type chest_xray --epochs 30 --batch_size 32 --lr 0.001
```

#### 5. Evaluate Model
```bash
# Evaluate on test dataset
python src/evaluate.py --model models/resnet_chest_xray.pth --data datasets/chest_xray/test

# Predict on single image
python src/evaluate.py --model models/resnet_chest_xray.pth --image path/to/image.jpg
```

### ğŸ–¥ï¸ Frontend Setup

#### 1. Navigate to Frontend Directory
```bash
cd frontend
```

#### 2. Install Dependencies
```bash
npm install
```

#### 3. Run Development Server
```bash
npm run dev
```
Visit: [http://localhost:5173](http://localhost:5173)

#### 4. Build for Production
```bash
npm run build
```
Production files will be output to the `dist/` folder.

## ğŸ—‚ Project Structure

```
MedNet1/
â”œâ”€â”€ frontend/             # React frontend (Vite)
â”‚   â”œâ”€â”€ src/              # Components and pages
â”‚   â”œâ”€â”€ public/           # Static assets
â”‚   â”œâ”€â”€ package.json      # Frontend dependencies
â”‚   â””â”€â”€ vite.config.js    # Vite configuration
â”œâ”€â”€ src/                  # Model training and evaluation scripts
â”‚   â”œâ”€â”€ train.py          # Model training script
â”‚   â””â”€â”€ evaluate.py       # Model evaluation script
â”œâ”€â”€ utils/                # Dataset setup helpers
â”‚   â””â”€â”€ data_utils.py     # Dataset utility functions
â”œâ”€â”€ datasets/             # Dataset storage (user generated)
â”œâ”€â”€ models/               # Saved model checkpoints
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # Project documentation
â””â”€â”€ LICENSE               # MIT License
```

## ğŸ“– Usage

### Training a Model
1. Prepare your dataset using the data utility
2. Run the training script with appropriate parameters
3. Monitor training progress and metrics

### Making Predictions
1. Load a trained model
2. Use the evaluation script for batch predictions or single image analysis
3. View results with confidence scores

### Using the Web Interface
1. Start the React development server
2. Upload medical images through the web interface
3. View predictions with confidence scores and explanations

## ğŸ”§ Customization

### Model Architecture
- **Switch Models:** Replace ResNet18 with DenseNet, EfficientNet, or other architectures in `train.py`
- **Hyperparameter Tuning:** Adjust learning rates, batch sizes, and epochs for optimal performance

### Dataset Extension
- **Add New Modalities:** Extend dataset creation and training logic to support additional medical image types
- **Custom Classes:** Modify class definitions for specific use cases

### Frontend Enhancement
- **UI Improvements:** Add feedback forms, zoom tools, or heatmap overlays
- **Visualization:** Integrate advanced visualization libraries for better result presentation

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature-name`)
3. Commit your changes (`git commit -m 'Add feature'`)
4. Push to the branch (`git push origin feature-name`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python code
- Use ESLint and Prettier for JavaScript/React code
- Include tests for new features
- Update documentation as needed

## âš ï¸ Disclaimer

**IMPORTANT:** This project is for research and educational purposes only. It is not intended for use in actual medical diagnosis or treatment. Always consult a licensed medical professional for medical advice and diagnosis.

## ğŸ“ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ™Œ Acknowledgements

- [PyTorch](https://pytorch.org/) - Deep learning framework
- [React](https://reactjs.org/) - Frontend library
- [Vite](https://vitejs.dev/) - Build tool
- Public medical image datasets from [Kaggle](https://kaggle.com) and other open repositories
- [ResNet Architecture](https://arxiv.org/abs/1512.03385) - Original paper

---

<div align="center">
  Made with â¤ï¸ for the medical AI community
</div>